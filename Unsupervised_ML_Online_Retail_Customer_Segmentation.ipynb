{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "mDgbUHAGgjLW",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "Fze-IPXLpx6K",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejaswini-meshram/Unsupervised-ML---Online-Retail-Customer-Segmentation/blob/main/Unsupervised_ML_Online_Retail_Customer_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Member** - Tejaswini Meshram"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project,the task is to identify major customer segments on a transnational data set that contained one-year historical transactions for a UK-based online retail store. This would help the company segregate its customers based on transaction data and help them in marketing decisions and strategy.\n",
        "\n",
        "After basic exploration and cleaning the data relationships between features in EDA was found and then jumped into the analysis part. RFM analysis helped us to identify the Platinum and Gold Customers who brings more profit for the Online retail stores as well helped to focus on Silver and Broze type of customer by organising some attractive offers for them.\n",
        "\n",
        "I implemented various unsupervised machine learning algorithm such as KMeans Clustering, DBSCAN Algorithm, Hierarchical Clustering (Agglomerative Clustering). Here to find the Optimal number of clusters I used a Elbow Visulizers by Yellow bricks from Scikit Learn library. Also used Silhouette Score and Silhouette plot to visualize the clusters with different number of clusters. For Agglomerative Clustering, Dendogram to find the optimal number of clusters is used."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, your task is to identify major customer segments on a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "HsECjYqHczFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lxry3oNYdF5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/content/Online Retail.xlsx - Online Retail.csv\")\n"
      ],
      "metadata": {
        "id": "zdmZP59adPSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "shape=df.shape\n",
        "print('rows = ',shape[0])\n",
        "print('columns = ',shape[1])"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#droping all the duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "YmONfbtohYZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number of unique rows\n",
        "df.shape[0]"
      ],
      "metadata": {
        "id": "KFwdYpFuhqfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(15,5))\n",
        "sns.heatmap(df.isnull(),cmap='plasma',annot=False,yticklabels=False)\n",
        "plt.title(\"Visualizing the missing values\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "1MWm8HOPkUOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "HskyhSU4kdTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Online Retail Dataset originally have 541909 rows and 8 columns out of which 5268 rows are duplicate.\n",
        "\n",
        "Datatype of Invoice Date is object need to convert it into datetime.\n",
        "\n",
        "CustomerID and Description have 135037 and 1454 missing values respectively. Customer ID is our identification feature so if it is not present then other details are of no use.\n",
        "\n",
        "So after droping all the missing values, we have 401604 rows.\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. InvoiceNo: Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n",
        "\n",
        "2. StockCode: Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n",
        "\n",
        "3. Description: Product (item) name. Nominal.\n",
        "\n",
        "4. Quantity: The quantities of each product (item) per transaction. Numeric.\n",
        "\n",
        "5. InvoiceDate: Invice Date and time. Numeric, the day and time when each transaction was generated.\n",
        "\n",
        "6. UnitPrice: Unit price. Numeric, Product price per unit in sterling.\n",
        "\n",
        "7. CustomerID: Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n",
        "\n",
        "8. Country: Country name. Nominal, the name of the country where each customer resides."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.apply(lambda col: col.unique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# quantity column has negative value which need to be removed\n",
        "df[df['Quantity']<0]"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# changing the datatype to str\n",
        "df['InvoiceNo'] = df['InvoiceNo'].astype('str')"
      ],
      "metadata": {
        "id": "6CVJa0PaPZ4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# InvoiceNo starting with C are cancelled so droping them\n",
        "df = df[-df['InvoiceNo'].str.contains('C')]"
      ],
      "metadata": {
        "id": "scuw4UcUPtkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape[0]"
      ],
      "metadata": {
        "id": "huVrD7rVSKKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rows with unit price as 0\n",
        "len(df[df['UnitPrice']==0])"
      ],
      "metadata": {
        "id": "VEXzHG_FQNWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# droping the rows with unit price 0\n",
        "df=df[df['UnitPrice']>0]\n",
        "df.shape"
      ],
      "metadata": {
        "id": "iU4RVtVxTCnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "ZOgeXadTTopz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As quantity of product cannot be negative therefore the rows with quntity value less than 0 are droped.\n",
        "\n",
        "InvoiceNo starting with C are cancelled so they are also droped."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Top 10 items\n",
        "\n",
        "top_10_products = df['Description'].value_counts().reset_index()\n",
        "top_10_products =top_10_products.iloc[:10]"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_products"
      ],
      "metadata": {
        "id": "8-AiVBYRRdYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x =top_10_products['count'], y=top_10_products['Description'] )\n",
        "plt.title('Top 10 Products')\n",
        "plt.ylabel('Product Name')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f73ZgsCrQNB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar chart is used to represent the top 10 products as it becomes easy to perform a comparison of metric values across different product of data."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart we can say that WHITE HANGING HEART T-LIGHT HOLDER is most popular and to 10 products counts more than 1000."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top selling products brings high revenue generation so more preference should be given to them."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#  10 least selling items\n",
        "\n",
        "least_10_products = df['Description'].value_counts().reset_index()\n",
        "least_10_products =least_10_products.tail(10)"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "least_10_products"
      ],
      "metadata": {
        "id": "xVxM1LN-xVOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x =least_10_products['count'], y=least_10_products['Description'] )\n",
        "plt.title('Least 10 Products')\n",
        "plt.ylabel('Product Name')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AlegAQJqyWnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar chart is used to represent the least 10 products as it becomes easy to perform a comparison of metric values across different product of data."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above graph we can say that least quantity ordered is 1 and listed are 10 least seld products."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strategic planning should involve a balanced approach, considering the potential of these least sold products."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#  top 10 stockcodes\n",
        "\n",
        "top_10_stockcodes = df['StockCode'].value_counts().reset_index()\n",
        "top_10_stockcodes =top_10_stockcodes.head(10)"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_stockcodes"
      ],
      "metadata": {
        "id": "48iy-AAR2QPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x =top_10_stockcodes['count'], y=top_10_stockcodes['StockCode'] )\n",
        "plt.title('top_10_stockcodes')\n",
        "plt.ylabel('Product Name')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JeljF02X2UNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar chart is used to represent the top 10 products as it becomes easy to perform a comparison of metric values across different product of data."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "StockCode-85123A is the first highest selling product.\n",
        "\n",
        "StockCode-22423 is the second highest selling product."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top selling products with these StockCodes brings high revenue generation so more preference should be given to them."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "#  top countries with most customers\n",
        "\n",
        "top_countries = df['Country'].value_counts().reset_index()\n",
        "top_countries =top_countries.head(5)"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_countries"
      ],
      "metadata": {
        "id": "fC5iJVET6GgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.pie(data=top_countries,x=top_countries.loc[:,'count'],startangle=90,labels='count',labeldistance=0.8)\n",
        "plt.legend(top_countries.loc[:,'Country'])\n",
        "plt.title(\"TOP 10 COUNTRIES WITH MOST CUSTOMERS\",color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dDQz1a9w6MAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show the distribution of top 10 counties with most customerss we use pie chart.Pie chart is the most suitable one as the pie chart visualizes the data distribution effectively and analysis becomes easier."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "UK has highest number of customers.\n",
        "\n",
        "Germany, France and IreLand has almost equal number of customers."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While having a large number of customers from a particular country (UK) is positive, over-dependency on specific markets may pose a risk. Economic or geopolitical changes in that country could impact travel patterns, leading to a potential downturn in business.\n",
        "\n",
        "It's essential for businesses to be mindful of potential risks associated with market dependency and consider strategies for diversification and staying competitive in the long run."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "#  sales in different months\n",
        "\n",
        "sales_in_month = df['month'].value_counts().reset_index()\n",
        "sales_in_month"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(x=sales_in_month['month'], y=sales_in_month['count'])\n",
        "plt.title(\"Sales count in Months\")"
      ],
      "metadata": {
        "id": "PwwU4Shd8ayY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar chart is used to represent the Sales count in Months as it becomes easy to perform a comparison of metric values across different product of data."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart we can say that November month has highest numnber of sales followed by October, December and September.\n",
        "Other all months have more or less the same number of sales."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As November Month has high sales, the inventaories should be managed and this month should be of high target to increase the revenue generation.\n",
        "\n",
        "Also Strategic planning should involve a balanced approach, considering the potential of other months and work upon it."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "#  sales on basis of days\n",
        "sales_in_day = df['Day'].value_counts().reset_index()\n",
        "sales_in_day\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(x=sales_in_day['Day'], y=sales_in_day['count'])\n",
        "plt.title(\"Sales count on different Days\")"
      ],
      "metadata": {
        "id": "p9Zc4YFIb4gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar chart is used to represent the Sales count on different days as it becomes easy to perform a comparison of metric values across different product of data."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sales on Thursdays are high and on Fridays are less compared to other days.\n",
        "\n",
        "Other days have almost equal number of sales."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As Thursdays has high sales, these days should be of high target to increase the revenue generation.\n",
        "\n",
        "Also Strategic planning should involve a balanced approach, considering the potential of other days and work upon it."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting InvoiceDate datatype to datetime in format 01-01-2010 01:00\n",
        "df[\"InvoiceDate\"]= pd.to_datetime(df[\"InvoiceDate\"])\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"year\"]= df[\"InvoiceDate\"].apply(lambda x: x.year)\n",
        "df[\"month_num\"]= df[\"InvoiceDate\"].apply(lambda x: x.month)\n",
        "df[\"day_num\"]= df[\"InvoiceDate\"].apply(lambda x: x.day)\n",
        "df[\"hour\"]= df[\"InvoiceDate\"].apply(lambda x: x.hour)\n",
        "df[\"minute\"]= df[\"InvoiceDate\"].apply(lambda x: x.minute)\n"
      ],
      "metadata": {
        "id": "sekXmdqJAAGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting month from Invoice date\n",
        "df[\"month\"]=df[\"InvoiceDate\"].dt.month_name()"
      ],
      "metadata": {
        "id": "iWWij4yFCUAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting day from Invoice date\n",
        "df[\"Day\"]=df[\"InvoiceDate\"].dt.day_name()"
      ],
      "metadata": {
        "id": "QBhkzhKaCvuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"TotalAmount\"]=df[\"Quantity\"]*df[\"UnitPrice\"]"
      ],
      "metadata": {
        "id": "AvjD4V0uDPjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "NzPBO6UMDgX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RFM Model Analysis\n",
        "\n",
        "rfm_df=df.copy()\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recency = Latest Date - Last Invoice Date,  Frequency = count of invoice no. of transactions, Monetary = Sum of Total Amount for each Costomer\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "# set latest date 2011-12-10 as last invoice date was 2011-12-09\n",
        "Latest_Date= dt.datetime(2011,12,10)\n",
        "\n",
        "#create RFM model score for each customer\n",
        "rfm_df = df.groupby('CustomerID').agg({'InvoiceDate': lambda x:(Latest_Date-x.max()).days,\n",
        "                                       'InvoiceNo': lambda x:len(x),\n",
        "                                       'TotalAmount': lambda x: x.sum()})\n",
        "\n",
        "#convert Invoice date into type int\n",
        "rfm_df['InvoiceDate'] = rfm_df['InvoiceDate'].astype(int)\n",
        "\n",
        "#rename column names to Recency, Frequency, and Monetary\n",
        "rfm_df.rename(columns = {'InvoiceDate':'Recency',  'InvoiceNo': 'Frequency',  'TotalAmount': 'Monetary'}, inplace=True)\n",
        "\n",
        "rfm_df.reset_index().head()"
      ],
      "metadata": {
        "id": "uUlID3awinTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recency description\n",
        "rfm_df.Recency.describe()"
      ],
      "metadata": {
        "id": "y-yyu2Kx5uIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# recency description plot\n",
        "import seaborn as sns\n",
        "x = rfm_df['Recency']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(x,color='b')"
      ],
      "metadata": {
        "id": "pYNVc82t56o7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frequency description\n",
        "rfm_df.Frequency.describe()"
      ],
      "metadata": {
        "id": "wpPrrGFQ6fl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency description plot\n",
        "import seaborn as sns\n",
        "x = rfm_df['Frequency']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(x,color='b')"
      ],
      "metadata": {
        "id": "Xp52afC97MB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# monetary description\n",
        "rfm_df.Monetary.describe()"
      ],
      "metadata": {
        "id": "EfXOi6kQ70KX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# monetary description plot\n",
        "import seaborn as sns\n",
        "x = rfm_df['Monetary']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(x,color='b')"
      ],
      "metadata": {
        "id": "1W555UiD77zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Observation\n",
        "\n",
        "From all the above graphs of Recency, Frequency and Monetary we can say that all are positively skewed distribution."
      ],
      "metadata": {
        "id": "QCOTp_9Y9Gr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into four segments using quantiles\n",
        "# Converting quantiles to a dictionary making it easy to use\n",
        "\n",
        "quantiles = rfm_df.quantile(q=[0.25,0.5,0.75])\n",
        "quantiles = quantiles.to_dict()\n",
        "quantiles"
      ],
      "metadata": {
        "id": "MQR6SU8r9nqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Function to create R, F and M segments\n",
        "# arguments (x= value, p= recency,monetary_value,frequency,d=quartiles dict)\n",
        "#lower the recency, good for the company\n",
        "\n",
        "def RScoring(x,p,d):\n",
        "  if x <= d[p][0.25]:\n",
        "    return 1\n",
        "  elif x<= d[p][0.50]:\n",
        "    return 2\n",
        "  elif x<= d[p][0.75]:\n",
        "    return 3\n",
        "  else:\n",
        "    return 4\n",
        "\n",
        "\n",
        "# arguments (x= value, p= recency, monetary_value, frequency, d=quartiles dict)\n",
        "# higher value of frequency and monetary lead to a good customer.\n",
        "def FnMScoring(x,p,d):\n",
        "  if x <= d[p][0.25]:\n",
        "    return 4\n",
        "  elif x<= d[p][0.50]:\n",
        "    return 3\n",
        "  elif x<= d[p][0.75]:\n",
        "    return 2\n",
        "  else:\n",
        "    return 1\n"
      ],
      "metadata": {
        "id": "_EIPltvU_k__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating and adding R, F and M segments values columns in the existing dataset to show R, F, M segments\n",
        "\n",
        "rfm_df['R'] = rfm_df['Recency'].apply(RScoring,args=('Recency',quantiles,))\n",
        "rfm_df['F'] = rfm_df['Frequency'].apply(FnMScoring,args=('Frequency',quantiles,))\n",
        "rfm_df['M'] = rfm_df['Monetary'].apply(FnMScoring,args=('Monetary',quantiles,))\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "JSdtSRFtG04h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate and add RFM group value column showing combined concatenated score of RFM\n",
        "rfm_df['RFM_Group'] = rfm_df.R.map(str) + rfm_df.F.map(str) + rfm_df.M.map(str)\n",
        "\n",
        "#calculate and add RFMScore value column showing total sum of RFMGroup values\n",
        "rfm_df['RFM_Score'] = rfm_df[['R','F','M']].sum(axis = 1)\n",
        "\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "KY1L0od_JQoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_df.info()"
      ],
      "metadata": {
        "id": "S1Z3RaNKKmeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_df['RFM_Score'].unique()\n"
      ],
      "metadata": {
        "id": "a0fiunZuNBEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign loyalty_Level to each customer\n",
        "\n",
        "Loyalty_Level = ['Platinum', 'Gold', 'Silver', 'Bronz']\n",
        "Score_cut = pd.qcut(rfm_df['RFM_Score'], q=4, labels = Loyalty_Level)\n",
        "rfm_df['RFM_Loyalty_Level'] = Score_cut.values\n",
        "rfm_df.reset_index().head()"
      ],
      "metadata": {
        "id": "4jCzY4akNMwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validate the data for RFM group = 111\n",
        "\n",
        "rfm_df[rfm_df['RFM_Group']=='111'].sort_values(\"Monetary\",ascending = False).reset_index().head(10)"
      ],
      "metadata": {
        "id": "0txxpCY3OQpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "sns.countplot(rfm_df['RFM_Loyalty_Level'])\n",
        "plt.title('Loyalty Level of Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I8YVA_EIOzYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling negative and zero values so as to handle infinite numbers during log transformation\n",
        "\n",
        "def handle_neg_n_zero(num):\n",
        "  if num <= 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return num\n",
        "\n",
        "#Applying handle_neg_n_zero function to Recency and Monetary columns\n",
        "\n",
        "rfm_df [ 'Recency'] = [handle_neg_n_zero(x) for x in rfm_df.Recency]\n",
        "rfm_df [ 'Monetary'] = [handle_neg_n_zero(x) for x in rfm_df.Monetary]\n",
        "\n",
        "#Performing Log transformation to bring data into normal or near normal distribution\n",
        "Log_Tfd_Data = rfm_df [['Recency', 'Frequency', 'Monetary']].apply(np.log, axis = 1).round(3)\n",
        "\n",
        "#Data distribution after data normalization for Recency\n",
        "Recency_Plot = Log_Tfd_Data['Recency']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(Recency_Plot,color = 'b')"
      ],
      "metadata": {
        "id": "9nZqAfq1Q_mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data distribution after data normalization for frequency\n",
        "Frequency_Plot = Log_Tfd_Data.query('Frequency < 100')['Frequency']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(Frequency_Plot, color= 'b')"
      ],
      "metadata": {
        "id": "elGHSOS_SDZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "rfm_df['Recency_log'] = rfm_df['Recency'].apply(math.log)\n",
        "\n",
        "rfm_df['Frequency_log'] = rfm_df['Frequency'].apply(math.log)\n",
        "\n",
        "rfm_df['Monetary_log'] = rfm_df['Monetary'].apply(math.log)"
      ],
      "metadata": {
        "id": "01j0I_NoZlQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_df"
      ],
      "metadata": {
        "id": "2B0qPL56ajAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K Mean Clustering   (Elbow method)\n",
        "\n"
      ],
      "metadata": {
        "id": "V6rPCz8uTXjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries necessary for clustering\n",
        "\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "qkx6HprWTWha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yellowbrick"
      ],
      "metadata": {
        "id": "4-T0QoSwVnKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying Elbow method an Recency and Monetary\n",
        "\n",
        "# taking Recency and Monetory_log in list.\n",
        "Recency_and_Monetary_feat=['Recency_log', 'Monetary_log']\n",
        "\n",
        "# taking only values of recency and monetory in X.\n",
        "X= rfm_df[Recency_and_Monetary_feat].values\n",
        "\n",
        "# standardising the data\n",
        "scaler= StandardScaler()\n",
        "X=scaler.fit_transform(X)\n",
        "\n",
        "#applying Elbow Method\n",
        "\n",
        "wcss = {}\n",
        "\n",
        "for k in range(1,15):\n",
        "  km = KMeans (n_clusters= k, init ='k-means++', max_iter= 1000)\n",
        "  km=km.fit(X)\n",
        "  wcss[k] = km.inertia_\n",
        "\n",
        "#Plot the graph for the sum of square distance values and Number of Clusters\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.pointplot(x=list(wcss.keys()),y = list(wcss.values()))\n",
        "plt.xlabel('Number of Clusters(k)')\n",
        "plt.ylabel(\"Sum of Squared Distances\")\n",
        "plt.title('Elboe method for Optimal k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wSbyFZ_hVysF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that optimal value for cluster came out to be 2."
      ],
      "metadata": {
        "id": "_E5SHAJoh2rG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Instantiate the clustering model and visualizer\n",
        "\n",
        "model =KMeans()\n",
        "\n",
        "visualizer =KElbowVisualizer( model, k=(2,12), metric='calinski_harabasz', timings=False )\n",
        "\n",
        "visualizer.fit(X)  # Fit the data to the visualizer\n",
        "\n",
        "visualizer.show()  #Finalize and render the figure"
      ],
      "metadata": {
        "id": "fBjalOXFihww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(X)\n",
        "y_kmeans= kmeans.predict(X)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.title('customer segmentation based on Recency and Monetary')\n",
        "plt.scatter(X[:,0],X[:,1], c=y_kmeans, s=50, cmap='spring_r')\n",
        "\n",
        "centres= kmeans.cluster_centers_\n",
        "plt.scatter(centers[:,0],centers[:,1], c='black', s=200, alpha=0.5)"
      ],
      "metadata": {
        "id": "u70IDQPm0Zgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Silhouette Score"
      ],
      "metadata": {
        "id": "x8Hl4dGLjGPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validating above optimal cluster value (i.e. optimal_cluster=2)\n",
        "# taking Recency and Monetory_log in list.\n",
        "Recency_and_Monetary_feat=['Recency_log', 'Monetary_log']\n",
        "\n",
        "# taking only values of recency and monetory in X.\n",
        "X=rfm_df[Recency_and_Monetary_feat].values\n",
        "\n",
        "# standardising the data\n",
        "scaler=StandardScaler()\n",
        "X=scaler.fit_transform(X)\n",
        "\n",
        "#Silhouette Score\n",
        "range_n_clusters = [2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "for n_clusters in range_n_clusters:\n",
        "  clusterer = KMeans(n_clusters=n_clusters, random_state=1)\n",
        "  preds =clusterer.fit_predict(X)\n",
        "  centers= clusterer.cluster_centers_\n",
        "\n",
        "  score =silhouette_score(X, preds)\n",
        "  print(\"For n_clusters = {}, silhouette score is {}\".format(n_clusters, score))"
      ],
      "metadata": {
        "id": "rGwbE9y_jFxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Observation\n",
        "Here we can see the for n_cluster=2 silhouette score is good as compared to others. (if values is close to 1 means data points are clustered very well to respective clusters and distance of that datapoint is very far from the other cluster.)"
      ],
      "metadata": {
        "id": "BEFsvmRuki-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.cm as cm"
      ],
      "metadata": {
        "id": "Ys9W1Nijrxip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_features = rfm_df[['Recency_log',\t'Frequency_log',\t'Monetary_log']].values\n",
        "saler= preprocessing.StandardScaler()\n",
        "X= saler.fit_transform(X_features)\n",
        "\n",
        "range_n_clusters = [2,3,4,5,6,7,8,9,10]\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "  # Create a subplot with 1 row and 2 columns\n",
        "  fig , (ax1, ax2) = plt.subplots(1, 2)\n",
        "  fig.set_size_inches (18, 7)\n",
        "\n",
        "  # The 1st subplot is the silhouette plot\n",
        "  # The silhouette coefficient can range from 1, 1 but in this example all lie within [-0.1, 1]\n",
        "  ax1.set_xlim([-0.1, 1])\n",
        "\n",
        "  # The (n_clusters+1)*10 is for inserting blank space between silhouette plots of individual clusters, to demarcate them clearly.\n",
        "  ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "\n",
        "  # Initialize the clusterer with n_clusters value and a random generator seed of 10 for reproducibility.\n",
        "\n",
        "  clusterer =KMeans(n_clusters=n_clusters, random_state=10)\n",
        "  cluster_labels = clusterer.fit_predict(X)\n",
        "\n",
        "  # The silhouette_score gives the average value for all the samples.\n",
        "  # This gives a perspective into the density and separation of the formed clusters\n",
        "\n",
        "  silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "  print(\"For n_clusters =\", n_clusters, \"The average silhouette_score is\", silhouette_avg)\n",
        "\n",
        "  # Compute the silhouette scores for each sample\n",
        "  sample_silhouette_values = silhouette_samples (X, cluster_labels)\n",
        "\n",
        "  y_lower = 10\n",
        "\n",
        "  for i in range(n_clusters):\n",
        "    #Aggregate the silhouette scores for samples belonging to cluster i, and sort them\n",
        "    ith_cluster_silhouette_values = \\\n",
        "       sample_silhouette_values[cluster_labels == i]\n",
        "\n",
        "    ith_cluster_silhouette_values.sort()\n",
        "\n",
        "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "    y_upper = y_lower + size_cluster_i\n",
        "\n",
        "    color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "    ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, facecolor=color, edgecolor=color,alpha=0.7)\n",
        "\n",
        "    # Label the silhouette plots with their cluster numbers at the middle\n",
        "    ax1.text(-0.05, y_lower+ 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "    # Compute the new y_lower for next plot\n",
        "    y_lower = y_upper + 10 # 10 for the 0 samples\n",
        "\n",
        "  ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "  ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "  ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "  # The vertical line for average silhouette score of all the values\n",
        "  ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "  ax1.set_yticks ([]) # Clear the yaxis labels / ticks\n",
        "  ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "  #2nd Plot showing the actual clusters formed\n",
        "  colors = cm.nipy_spectral(cluster_labels.astype (float) /n_clusters)\n",
        "  ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7, c=color, edgecolor='k')\n",
        "\n",
        "  #Labeling the clusters\n",
        "  centers= clusterer.cluster_centers_\n",
        "  #Draw white circles at cluster centers\n",
        "  ax2.scatter(centers[:, 0], centers[:, 1], marker='o', c=\"white\", alpha=1, s=200, edgecolor='k')\n",
        "\n",
        "  for i, c in enumerate(centers):\n",
        "    ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50, edgecolor='k')\n",
        "\n",
        "  ax2.set_title(\"The visualization of the clustered data.\")\n",
        "  ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "  ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "  plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \" \"with n_clusters= %d\" % n_clusters), fontsize =14, fontweight= 'bold')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Xc3HNHSZlDLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Observation\n",
        "\n",
        "From the silhouette analysis, it is clearly understood that, 2 clusters are performing best. Hence, 2 clusters will be selected to build the KMeans model and classify the customers."
      ],
      "metadata": {
        "id": "bp8cWKQmtSOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cluster by Recency, Frequency and Monetary\n",
        "# KMeans with 2 clusters\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(X)\n",
        "\n",
        "y_kmeans= kmeans.predict(X)\n",
        "\n",
        "#plotting figure\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "plt.title('customer segmentation based on Recency, Frequency and Monetary')\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='Spectral')\n",
        "\n",
        "centers =kmeans.cluster_centers_\n",
        "\n",
        "plt.scatter(centers [:, 0], centers [:, 1], c='yellow', s=200, alpha=0.5);"
      ],
      "metadata": {
        "id": "I5sFTykk9wLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Applying DBSCAN to Recency, Frequency and Monetary\n",
        "\n"
      ],
      "metadata": {
        "id": "9LSjHcfm_bmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn import metrics\n",
        "\n",
        "y_pred = DBSCAN(eps=0.5, min_samples=15).fit_predict(X)\n",
        "\n",
        "plt.figure(figsize=(13,8))\n",
        "\n",
        "plt.scatter(X[:,0], X[:,1], c=y_pred, cmap='hot');"
      ],
      "metadata": {
        "id": "fDE2Lcj3_gIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observtion\n",
        "\n",
        "Here we can see that, Customers are well seperated when we cluster them by Recency, Frequency and Monetary and opyimal number of cluster is equal to 3."
      ],
      "metadata": {
        "id": "-QC8_QYaAIKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing K-Means Clustering with 2 clusters\n",
        "\n",
        "KMean_clust = KMeans(n_clusters= 2, init ='k-means++', max_iter= 1000)\n",
        "KMean_clust.fit(X)\n",
        "\n",
        "#Find the clusters for the observation given in the dataset\n",
        "\n",
        "rfm_df ['Cluster'] = KMean_clust.labels_\n",
        "\n",
        "#First 10 rows of the RFM dataframe\n",
        "\n",
        "rfm_df.head (10)"
      ],
      "metadata": {
        "id": "YzQ-F8xLA0Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking customer belongs to cluster 1\n",
        "rfm_df[rfm_df['Cluster']==1]"
      ],
      "metadata": {
        "id": "MD0amJVmBO_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check mean values of the cluster for recency, frequeny and monetary\n",
        "rfm_df.groupby('Cluster').agg({'Recency':'mean', 'Frequency':'mean', 'Monetary':'mean'})"
      ],
      "metadata": {
        "id": "Vx54xSfCB1sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Observation\n",
        "We can see from above that the customer belongs to cluster 0 are premium customers and we can keep them in comapny's loyalty program and for the customer belongs to cluster 1 we can provide them offer or create some strategies for them so that they will do more transaction with us."
      ],
      "metadata": {
        "id": "zteU1qp5C3vm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Summary"
      ],
      "metadata": {
        "id": "rg-n9JlkEwJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "#Specify the column Names while initializing the Table\n",
        "myTable = PrettyTable(['Sr No.',\"Model_Name\", 'Data', \"Optimal_Number_of_cluster\"])\n",
        "\n",
        "#Add rows\n",
        "\n",
        "myTable.add_row(['1', \"K-Means with silhouette_score\", \"RM\", \"2\"])\n",
        "\n",
        "myTable.add_row(['2', \"K-Means with Elbow methos \", \"RM\", \"2\"])\n",
        "\n",
        "myTable.add_row(['3', \"DBSCAN\", \"RM\", \"2\"])\n",
        "\n",
        "myTable.add_row(['4', \"K-Means with silhouette_score\", \"FM\", \"2\"])\n",
        "\n",
        "myTable.add_row(['5', \"K-Means with Elbow methos \", \"FM\", \"2\"])\n",
        "\n",
        "myTable.add_row(['6', \"DBSCAN\", \"FM\", \"2\"])\n",
        "\n",
        "myTable.add_row(['7', \"K-Means with silhouette_score\", \"RFM\", \"2\"])\n",
        "\n",
        "myTable.add_row(['8', \"K-Means with Elbow methos\", \"RFM\", \"2\"])\n",
        "\n",
        "\n",
        "print(myTable)"
      ],
      "metadata": {
        "id": "-BLNRvIgEyFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In unsupervised machine learning, especially for tasks like online retail customer segmentation, the evaluation metrics are crucial in determining the quality and business impact of the segmentation. Here are some commonly considered evaluation metrics and their importance:\n",
        "\n",
        "1. Silhouette Score:\n",
        "\n",
        "The silhouette score measures how similar an object is to its own cluster compared to other clusters. A high silhouette score indicates that the clusters are well-defined, and customers within the same cluster are similar while being distinct from those in other clusters. This helps ensure that the segments are meaningful and can lead to better-targeted marketing strategies.\n",
        "\n",
        "2. Within-Cluster Sum of Squares (WCSS):\n",
        "\n",
        "WCSS measures the sum of squared distances between each point and the centroid of its cluster. Minimizing WCSS leads to more compact clusters, which can be crucial for identifying homogeneous customer segments that can be effectively targeted.\n",
        "\n",
        "3. Cluster Size and Distribution:\n",
        "\n",
        "Evaluating the size and distribution of clusters ensures that segments are balanced and actionable. If clusters are too small, they may not be significant for business strategies. Conversely, very large clusters might be too heterogeneous, reducing the precision of targeted marketing efforts.\n",
        "\n",
        "Using these metrics, the objective is to create customer segments that are not only statistically sound but also translate into positive business outcomes, such as improved customer targeting, personalized marketing strategies, and increased customer satisfaction and loyalty."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The elbow method was chosen as the final prediction model for the unsupervised machine learning task of online retail customer segmentation because it effectively balances simplicity and performance. By plotting the explained variance against the number of clusters, the elbow method helps identify the point where adding more clusters yields diminishing returns. This point, known as the \"elbow,\" provides a practical and intuitive way to select an optimal number of clusters, ensuring that the model remains interpretable while capturing essential patterns in the data.\n",
        "\n",
        "Additionally, the elbow method is computationally efficient and straightforward to implement, making it suitable for large datasets commonly encountered in retail customer segmentation. By preventing overfitting, it ensures that the segmentation remains generalizable to new data, thus enhancing the robustness of the model. This approach helps businesses understand customer behavior more accurately, facilitating targeted marketing strategies and improving overall customer satisfaction."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this analysis, the K-Means clustering algorithm was utilized to segment online retail customers based on Recency, Frequency, and Monetary (RFM) metrics. The K-Means algorithm was selected due to its simplicity and efficiency in handling large datasets. It works by partitioning the data into clusters where each data point belongs to the cluster with the nearest mean. The optimal number of clusters was determined using both the silhouette score and the elbow method, which both indicated that 2 clusters were optimal for this dataset. These clusters help in identifying different customer segments, such as premium customers and those who require targeted marketing strategies.\n",
        "\n",
        "To explain the importance of features and understand how the model segments customers, the SHAP tool can be employed. SHAP values provide a unified measure of feature importance by assigning each feature an importance value for a particular prediction. By applying SHAP to the K-Means model, we can visualize the contribution of Recency, Frequency, and Monetary value in determining customer segments. This helps in interpreting the model's decisions and understanding which features drive the clustering process. For instance, high Monetary values might indicate premium customers, while higher Recency values might identify less engaged customers, guiding strategic business decisions for loyalty programs and targeted offers."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project mainly focused on developing customer segments for a UK based online store, selling unique all occasion gifts.\n",
        "\n",
        "Using a recency, frequency and monetary (RFM) analysis, the customers have been segmented into various clusters and got a silhoutte score of 0.39 for two clusters\n",
        "\n",
        "By applying different clustering algorithm to our dataset, we get the optimal number of cluster is equal to 2.\n",
        "\n",
        "The business can focus on these different clusters and provide customer with services of each sector in a different way, which would not only benefit the customers but also the business at large."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}